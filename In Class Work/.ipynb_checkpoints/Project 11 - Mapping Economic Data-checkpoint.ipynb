{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c258411",
   "metadata": {},
   "source": [
    "# Project 11: Working with Geocoded Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f5fb4c",
   "metadata": {},
   "source": [
    "## Building Maps in geopandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "132f959a",
   "metadata": {},
   "source": [
    "In this lesson we will download COVID-19 data from data.world. We will normalize the data to compare spread between counties. Were we to simply plot the total number of cases or deaths by county, the results would be biased as counties with larger populations would likely have more cases and more deaths. We will observe how the spread developed across the country, starting in the northeast, eventually making its way to other regions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d764ced",
   "metadata": {},
   "source": [
    "### Installing geopandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc0a1d9a",
   "metadata": {},
   "source": [
    "Although there is a geopandas installation available using the conda install command in you command line shell, that package is incomplete for our purposes. We will need to install dependencies - in this order: GDAL,Fiona, and Shapely - for geopandas before installing geopandas. I have included the .whl files for each of these packages in the same folder is this notebook. Download the files and save them to your local folder. To install, use the command:\n",
    "\n",
    "pip install filename"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b1af22a",
   "metadata": {},
   "source": [
    "Finally, install geopandas:\n",
    "\n",
    "pip install geopandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "414ceb46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting datadotworld\n",
      "  Downloading datadotworld-1.8.5-py2.py3-none-any.whl (423 kB)\n",
      "Requirement already satisfied: python-dateutil<3.0a,>=2.6.0 in c:\\users\\owner\\anaconda3.0\\lib\\site-packages (from datadotworld) (2.8.2)\n",
      "Collecting tableschema<2.0a,>=1.5.2\n",
      "  Downloading tableschema-1.20.2-py2.py3-none-any.whl (68 kB)\n",
      "Requirement already satisfied: six<2.0a,>=1.5.0 in c:\\users\\owner\\anaconda3.0\\lib\\site-packages (from datadotworld) (1.16.0)\n",
      "Requirement already satisfied: requests<3.0a,>=2.22.0 in c:\\users\\owner\\anaconda3.0\\lib\\site-packages (from datadotworld) (2.26.0)\n",
      "Requirement already satisfied: certifi>=2017.04.17 in c:\\users\\owner\\anaconda3.0\\lib\\site-packages (from datadotworld) (2021.10.8)\n",
      "Collecting datapackage<2.0a,>=1.6.2\n",
      "  Downloading datapackage-1.15.2-py2.py3-none-any.whl (85 kB)\n",
      "Collecting tabulator>=1.22.0\n",
      "  Downloading tabulator-1.53.5-py2.py3-none-any.whl (72 kB)\n",
      "Requirement already satisfied: urllib3<2.0a,>=1.15 in c:\\users\\owner\\anaconda3.0\\lib\\site-packages (from datadotworld) (1.26.7)\n",
      "Collecting configparser<4.0a,>=3.5.0\n",
      "  Downloading configparser-3.8.1-py2.py3-none-any.whl (22 kB)\n",
      "Requirement already satisfied: click<9.0a,>=8.0 in c:\\users\\owner\\anaconda3.0\\lib\\site-packages (from datadotworld) (8.0.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\owner\\anaconda3.0\\lib\\site-packages (from click<9.0a,>=8.0->datadotworld) (0.4.4)\n",
      "Requirement already satisfied: jsonschema>=2.5 in c:\\users\\owner\\anaconda3.0\\lib\\site-packages (from datapackage<2.0a,>=1.6.2->datadotworld) (3.2.0)\n",
      "Requirement already satisfied: chardet>=3.0 in c:\\users\\owner\\anaconda3.0\\lib\\site-packages (from datapackage<2.0a,>=1.6.2->datadotworld) (4.0.0)\n",
      "Requirement already satisfied: unicodecsv>=0.14 in c:\\users\\owner\\anaconda3.0\\lib\\site-packages (from datapackage<2.0a,>=1.6.2->datadotworld) (0.14.1)\n",
      "Collecting jsonpointer>=1.10\n",
      "  Downloading jsonpointer-2.3-py2.py3-none-any.whl (7.8 kB)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in c:\\users\\owner\\anaconda3.0\\lib\\site-packages (from jsonschema>=2.5->datapackage<2.0a,>=1.6.2->datadotworld) (0.18.0)\n",
      "Requirement already satisfied: attrs>=17.4.0 in c:\\users\\owner\\anaconda3.0\\lib\\site-packages (from jsonschema>=2.5->datapackage<2.0a,>=1.6.2->datadotworld) (21.2.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\owner\\anaconda3.0\\lib\\site-packages (from jsonschema>=2.5->datapackage<2.0a,>=1.6.2->datadotworld) (58.0.4)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\owner\\anaconda3.0\\lib\\site-packages (from requests<3.0a,>=2.22.0->datadotworld) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\owner\\anaconda3.0\\lib\\site-packages (from requests<3.0a,>=2.22.0->datadotworld) (3.2)\n",
      "Requirement already satisfied: cached-property>=1.5 in c:\\users\\owner\\anaconda3.0\\lib\\site-packages (from tableschema<2.0a,>=1.5.2->datadotworld) (1.5.2)\n",
      "Collecting isodate>=0.5.4\n",
      "  Downloading isodate-0.6.1-py2.py3-none-any.whl (41 kB)\n",
      "Collecting rfc3986>=1.1.0\n",
      "  Downloading rfc3986-2.0.0-py2.py3-none-any.whl (31 kB)\n",
      "Requirement already satisfied: sqlalchemy>=0.9.6 in c:\\users\\owner\\anaconda3.0\\lib\\site-packages (from tabulator>=1.22.0->datadotworld) (1.4.22)\n",
      "Collecting jsonlines>=1.1\n",
      "  Downloading jsonlines-3.1.0-py3-none-any.whl (8.6 kB)\n",
      "Requirement already satisfied: xlrd>=1.0 in c:\\users\\owner\\anaconda3.0\\lib\\site-packages (from tabulator>=1.22.0->datadotworld) (2.0.1)\n",
      "Collecting linear-tsv>=1.0\n",
      "  Downloading linear-tsv-1.1.0.tar.gz (9.6 kB)\n",
      "Requirement already satisfied: openpyxl>=2.6 in c:\\users\\owner\\anaconda3.0\\lib\\site-packages (from tabulator>=1.22.0->datadotworld) (3.0.9)\n",
      "Collecting ijson>=3.0.3\n",
      "  Downloading ijson-3.2.0.post0-cp39-cp39-win_amd64.whl (48 kB)\n",
      "Collecting boto3>=1.9\n",
      "  Downloading boto3-1.26.132-py3-none-any.whl (135 kB)\n",
      "Collecting jmespath<2.0.0,>=0.7.1\n",
      "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
      "Collecting s3transfer<0.7.0,>=0.6.0\n",
      "  Downloading s3transfer-0.6.1-py3-none-any.whl (79 kB)\n",
      "Collecting botocore<1.30.0,>=1.29.132\n",
      "  Downloading botocore-1.29.132-py3-none-any.whl (10.7 MB)\n",
      "Requirement already satisfied: et-xmlfile in c:\\users\\owner\\anaconda3.0\\lib\\site-packages (from openpyxl>=2.6->tabulator>=1.22.0->datadotworld) (1.1.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\owner\\anaconda3.0\\lib\\site-packages (from sqlalchemy>=0.9.6->tabulator>=1.22.0->datadotworld) (1.1.1)\n",
      "Building wheels for collected packages: linear-tsv\n",
      "  Building wheel for linear-tsv (setup.py): started\n",
      "  Building wheel for linear-tsv (setup.py): finished with status 'done'\n",
      "  Created wheel for linear-tsv: filename=linear_tsv-1.1.0-py3-none-any.whl size=7399 sha256=8b40c5d24a4bdb67c93c1db665cb85602735d8dde7247c3e8df627710acfdd51\n",
      "  Stored in directory: c:\\users\\owner\\appdata\\local\\pip\\cache\\wheels\\b5\\eb\\b6\\e409f80d7fec532e4240dda9562cad374257d2dd010b40cfff\n",
      "Successfully built linear-tsv\n",
      "Installing collected packages: jmespath, botocore, s3transfer, linear-tsv, jsonlines, ijson, boto3, tabulator, rfc3986, isodate, tableschema, jsonpointer, datapackage, configparser, datadotworld\n",
      "Successfully installed boto3-1.26.132 botocore-1.29.132 configparser-3.8.1 datadotworld-1.8.5 datapackage-1.15.2 ijson-3.2.0.post0 isodate-0.6.1 jmespath-1.0.1 jsonlines-3.1.0 jsonpointer-2.3 linear-tsv-1.1.0 rfc3986-2.0.0 s3transfer-0.6.1 tableschema-1.20.2 tabulator-1.53.5\n"
     ]
    }
   ],
   "source": [
    "!pip install datadotworld"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1444b465",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'geopandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_18976/1877086143.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mgeopandas\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcm\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'geopandas'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28fb5d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "#def import_geo_data(filename, index_col = \"Date\", FIPS_name = \"FIPS\"):\n",
    "plt.rcParams.update({'font.size': 32})\n",
    "filename = \"countiesWithStatesAndPopulation.shp\"\n",
    "index_col = \"FIPS\"\n",
    "map_data = geopandas.read_file(filename = filename).set_index([\"State\", \n",
    "                                                               \"NAME\"])\n",
    "states = [\"North Dakota\", \n",
    "          \"South Dakota\", \n",
    "          \"Minnesota\"]\n",
    "map_plot_data = map_data.loc[states]\n",
    "state_df = map_plot_data.dissolve(by=[\"State\"], aggfunc = \"median\")\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (30,15))\n",
    "map_plot_data.plot(column = \"Population\", \n",
    "                   cmap = \"viridis\",\n",
    "                   alpha = 1, \n",
    "                   edgecolor = \"k\",\n",
    "                  ax = ax)\n",
    "state_df.plot(color = \"None\", \n",
    "                  alpha = 1,\n",
    "                  edgecolor = \"k\",\n",
    "                  linewidth = 8,\n",
    "                          ax = ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72fe6600",
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_geo_data(filename, FIPS_name = \"FIPS\"):\n",
    "    map_data = geopandas.read_file(filename = filename).rename(\n",
    "        columns = {\"State\":\"state\"})\n",
    "    map_data[FIPS_name] = map_data[\"STATEFP\"].astype(str) +\\\n",
    "        map_data[\"COUNTYFP\"].astype(str)\n",
    "    map_data[FIPS_name] = map_data[FIPS_name].astype(np.int64)\n",
    "    map_data.set_index(FIPS_name, inplace = True)\n",
    "    \n",
    "    return map_data\n",
    "map_data = import_geo_data(filename = filename, FIPS_name = index_col)\n",
    "map_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c592282c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot only counties not in Hawaii or Alaska, CONTINENTAL USA\n",
    "map_data[~map_data[\"state\"].isin(\n",
    "    [\"Hawaii\", \"Alaska\"])].plot(column = \"Population\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe15ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "u_data = pd.read_csv(\"countyUnemploymentData.csv\",\n",
    "                    encoding = \"latin1\",\n",
    "                    parse_dates = True,\n",
    "                    index_col = [\"date\", \"fips_code\"])\n",
    "u_data = u_data[list(u_data.keys())[-4:]]\n",
    "u_data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e811f4c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in u_data.keys():\n",
    "    u_data[key] = pd.to_numeric(u_data[key], errors = \"coerce\")\n",
    "u_data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "947409c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy as copy\n",
    "def create_merged_geo_dataframe(data, map_data):\n",
    "    data_frame_initialized = False\n",
    "    matching_gpd = {}\n",
    "    counties = data.groupby(\"fips_code\").mean().index.unique()\n",
    "    dates = data.groupby(\"date\").mean().index.unique()\n",
    "    for key, val in data.items():\n",
    "        matching_gpd[key] = copy.copy(\n",
    "            map_data[map_data.index.isin(counties)])\n",
    "        for date in dates:\n",
    "            val_slice = val.loc[date]\n",
    "            val_slice.reset_index().set_index(\"fips_code\")\n",
    "            matching_gpd[key][date] = val_slice\n",
    "    return matching_gpd\n",
    "dates = u_data.groupby(\"date\").mean().index.unique()\n",
    "u_data = create_merged_geo_dataframe(u_data, map_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef8f813",
   "metadata": {},
   "outputs": [],
   "source": [
    "u_data[\"Unemployment Rate\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d5b6b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# matplotlib will give us warning because we are setting the value a slice\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "# Normalize Unemployment Feb-20 == 1\n",
    "key = \"Unemployment Rate\"\n",
    "new_key = \"Normalized \" + key + \" (Feb 2020)\"\n",
    "# df.copy() makes a copy of the dataframe\n",
    "u_data[new_key] = u_data[key].copy()\n",
    "# take the difference between the observed rate and the Feb rate\n",
    "for date in dates:\n",
    "    u_data[new_key][date] = u_data[key][date].sub(\n",
    "        u_data[key][datetime.datetime(2020,2,1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7add4bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "u_data[new_key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec7329ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import cm\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "key = \"Unemployment Rate\"\n",
    "plot_data = u_data[key].copy()\n",
    "plot_data = plot_data[~plot_data[\"state\"].isin([\"Hawaii\", \"Alaska\"])]\n",
    "state_df = plot_data.dissolve(by=[\"state\"], aggfunc = \"median\")\n",
    "#for date in dates:\n",
    "fig, ax = plt.subplots(figsize = (40,20))\n",
    "    # dissolve performs groupby operation and aggregates geoids to the\n",
    "    #  level grouped by\n",
    "    \n",
    "vmin = -20\n",
    "vmax = 20\n",
    "    # choose color bar format (which colors? how many divisions?)\n",
    "cmap = cm.get_cmap(\"Reds\", 15)\n",
    "    # choose range of color bar values\n",
    "norm = cm.colors.Normalize(vmin = vmin, vmax = vmax)\n",
    "sm = cm.ScalarMappable(cmap = cmap, norm = norm)\n",
    "    # prepare space for colorbar on fig\n",
    "divider = make_axes_locatable(ax)\n",
    "size = \"5%\"\n",
    "cax = divider.append_axes(\"right\", \n",
    "                            size = size, \n",
    "                            pad = .1)\n",
    "    # add colorbar to space in fig\n",
    "cbar = fig.colorbar(sm, cax = cax, cmap = cmap)\n",
    "cbar.ax.tick_params(labelsize = 18)\n",
    "vals = list(cbar.ax.get_yticks())\n",
    "    # append max values from plot_df[dates] to vals for cbar\n",
    "vals.append(plot_data[dates].max().max())\n",
    "cbar.ax.set_yticklabels(vals)\n",
    "cbar.ax.set_ylabel(key, fontsize = 20)\n",
    "plot_data.plot(ax = ax, \n",
    "        cax = ax,\n",
    "        column = date,\n",
    "        cmap = cmap, legend = False,\n",
    "        linewidth = .1, edgecolor = \"white\",\n",
    "        norm = norm)\n",
    "    \n",
    "state_df.plot(color = \"None\", \n",
    "                alpha = 1,\n",
    "                edgecolor = \"k\",\n",
    "                linewidth = 5,\n",
    "                ax = ax)\n",
    "ax.set_title(str(date)[:10] + \"\\n\" + key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61710ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = new_key\n",
    "plot_data = u_data[key].copy()\n",
    "plot_data = plot_data[~plot_data[\"state\"].isin([\"Hawaii\", \"Alaska\"])]\n",
    "state_df = plot_data.dissolve(by=[\"state\"], aggfunc = \"median\")\n",
    "#for date in dates:\n",
    "fig, ax = plt.subplots(figsize = (40,20))\n",
    "    # dissolve performs groupby operation and aggregates geoids to the\n",
    "    #  level grouped by\n",
    "    \n",
    "vmin = -20\n",
    "vmax = 20\n",
    "    # choose color bar format (which colors? how many divisions?)\n",
    "cmap = cm.get_cmap(\"coolwarm\", 15)\n",
    "    # choose range of color bar values\n",
    "norm = cm.colors.Normalize(vmin = vmin, vmax = vmax)\n",
    "sm = cm.ScalarMappable(cmap = cmap, norm = norm)\n",
    "    # prepare space for colorbar on fig\n",
    "divider = make_axes_locatable(ax)\n",
    "size = \"5%\"\n",
    "cax = divider.append_axes(\"right\", \n",
    "                            size = size, \n",
    "                            pad = .1)\n",
    "    # add colorbar to space in fig\n",
    "cbar = fig.colorbar(sm, cax = cax, cmap = cmap)\n",
    "cbar.ax.tick_params(labelsize = 18)\n",
    "vals = list(cbar.ax.get_yticks())\n",
    "    # append max values from plot_df[dates] to vals for cbar\n",
    "vals.append(plot_data[dates].max().max())\n",
    "cbar.ax.set_yticklabels(vals)\n",
    "cbar.ax.set_ylabel(key, fontsize = 20)\n",
    "plot_data.plot(ax = ax, \n",
    "        cax = ax,\n",
    "        column = date,\n",
    "        cmap = cmap, legend = False,\n",
    "        linewidth = .5, edgecolor = \"white\",\n",
    "        norm = norm)\n",
    "    \n",
    "state_df.plot(color = \"None\", \n",
    "                alpha = 1,\n",
    "                edgecolor = \"k\",\n",
    "                linewidth = 5,\n",
    "                ax = ax)\n",
    "ax.set_title(str(date)[:10] + \"\\n\" + key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0433f024",
   "metadata": {},
   "source": [
    "## Create Interactive Map with Plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67528eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "key = \"Unemployment Rate\"\n",
    "plot_df = u_data[key]\n",
    "plot_df = plot_df.to_crs(epsg=4326).rename(\n",
    "    # transform dates to str because plotly will throw error\n",
    "    # if datetime format passed as key\n",
    "    columns = {date:str(date)[:10]for date in plot_df[dates].keys()})\n",
    "cname = str(dates[-1])[:10]\n",
    "plot_df[cname] = plot_df[cname].round(2)\n",
    "hover_name = \"NAME\"\n",
    "fig = px.choropleth_mapbox(plot_df.reset_index(),\n",
    "                          geojson = plot_df,#.reset_index(),\n",
    "                          locations = \"FIPS\",\n",
    "                          hover_name = hover_name,\n",
    "                           hover_data = [cname],\n",
    "                          color = cname,\n",
    "                           color_continuous_scale = \"ylgnbu\",\n",
    "                          center = {\"lat\":plot_df[\"geometry\"].centroid.y.mean(),\n",
    "                                    \"lon\":plot_df[\"geometry\"].centroid.x.mean()},\n",
    "                          zoom = 4,\n",
    "                          opacity = .6,\n",
    "                          title = key,\n",
    "                          mapbox_style = \"carto-positron\",\n",
    "                          height = 900)\n",
    "#fig.show()\n",
    "fig.write_html(key+\".html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca3e09e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "world = geopandas.read_file(geopandas.datasets.get_path('naturalearth_lowres')).to_crs(epsg=4326)\n",
    "world.set_index(\"iso_a3\", inplace = True)\n",
    "world"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f8b821",
   "metadata": {},
   "outputs": [],
   "source": [
    "EFW = pd.read_csv(\"fraserDataWithRGDPPC.csv\",\n",
    "                  index_col = [\"ISO_Code_3\",\"Year\"],\n",
    "                  parse_dates = True).rename(columns = {\"Summary\":\"EFW\"})\n",
    "EFW_keys = list(EFW.keys())[-7:]\n",
    "EFW\n",
    "#EFW_keys = [\"EFW\",\n",
    " #          \"Size of Government\",\n",
    "  #         \"Legal System and Property Rights\",\n",
    "   #        \"Sound Money\",\n",
    "    #       \"Freedom to Trade Internationally\",\n",
    "     #      \"Regulation\",\n",
    "      #     \"RGDP Per Capita\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31151faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a dataframe that is only 2018\n",
    "EFW_2018 = EFW[EFW.index.get_level_values(\n",
    "    \"Year\") == \"2018\"].reset_index().set_index(\"ISO_Code_3\")\n",
    "for key in EFW_keys:\n",
    "    world[key + \" 2018\"] = EFW_2018[key]\n",
    "world"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0811c6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cities = geopandas.read_file(geopandas.datasets.get_path('naturalearth_cities')).to_crs(epsg=4326)\n",
    "cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7560d9b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only show cities that appear to be in a country\n",
    "cities[\"Country\"] = \"\"\n",
    "#cities[\"Country\"].iloc[0] = \"ITA\"\n",
    "cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d5c1d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ix in cities.index:\n",
    "    try:\n",
    "        # save the name of the country if the city falls within its boundaries\n",
    "        cities.loc[ix, \"Country\"] = world[world[\"geometry\"].contains(cities.loc[ix][\"geometry\"])].index[0]\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47a39886",
   "metadata": {},
   "outputs": [],
   "source": [
    "cities[cities[\"Country\"] != \"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc96a27d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.patheffects as pe\n",
    "for key in EFW_keys:\n",
    "    column = key + \" 2018\"\n",
    "    fig, ax = plt.subplots(figsize = (40,30))\n",
    "    cmap = cm.get_cmap(\"Blues\", 20)\n",
    "    norm = cm.colors.Normalize(vmin = world[column].min(),\n",
    "                               vmax = world[column].max())\n",
    "    sm = cm.ScalarMappable(cmap = cmap,\n",
    "                          norm = norm)\n",
    "    # prepare space for colorbar\n",
    "    divider = make_axes_locatable(ax)\n",
    "    size = \"5%\"\n",
    "    cax = divider.append_axes(\"right\",\n",
    "                             size = size,\n",
    "                             pad = .1)\n",
    "    cbar = fig.colorbar(sm, cax = cax, cmap = cmap)\n",
    "    cbar.ax.tick_params(labelsize = 24)\n",
    "    vals = list(cbar.ax.get_yticks())\n",
    "    vals.append(vmax)\n",
    "    cbar.ax.set_yticklabels(vals)\n",
    "    \n",
    "    \n",
    "    world.plot(color = \"k\", alpha = .25, ax = ax)\n",
    "    world.plot(column = column,\n",
    "              cmap = cmap,\n",
    "               linewidth = 1,\n",
    "               edgecolor = \"k\",\n",
    "              ax = ax,\n",
    "              alpha = .95)\n",
    "    cities[cities[\"Country\"]!= \"\"].plot(color = \"C3\",\n",
    "                                       markersize = 35,\n",
    "                                       ax = ax)\n",
    "    \n",
    "    area = world.area\n",
    "    #add country label only if greater than or equal to size of Ireland\n",
    "    for ix in world.index:\n",
    "        if area[ix] >= area[\"IRL\"]:\n",
    "            centroid = world.loc[ix][\"geometry\"].representative_point()\n",
    "            x,y = centroid.x, centroid.y \n",
    "            ax.text(x, y, ix, va = \"center\", \n",
    "                    ha = \"center\", fontsize = 10,\n",
    "                   path_effects = [pe.withStroke(linewidth = .9, \n",
    "                                                 foreground = \"white\")])\n",
    "            \n",
    "    ax.set_title(column)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
