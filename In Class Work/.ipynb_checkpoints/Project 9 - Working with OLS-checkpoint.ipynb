{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3a0f482",
   "metadata": {},
   "source": [
    "# Project 9 - Working with OLS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29a5762d",
   "metadata": {},
   "source": [
    "Having built statistics functions, we are now ready to build a function for regression analysis. We will start by building the an regression. We will use linear algebra to estimate parameters that minimize the sum of the squared errors. This is an ordinary least squares regression.\n",
    "\n",
    "An OLS regression with one exogenous variable takes the form.\n",
    "\n",
    "y = alpha + (beta1)(x1) + mu\n",
    "\n",
    "Beta0 = alpha + mu\n",
    "\n",
    "We merge the error term, which represents bias in the data, with alpha to yield the constant, Beta0. This is necessary since OLS assumes an unbiased estimator where:\n",
    "\n",
    "Sum of ei = 0\n",
    "\n",
    "Each estimate of a point created from a particular observation takes the form.\n",
    "\n",
    "yi = Beta0 + (Beta1)(x1,i) + ei\n",
    "\n",
    "\n",
    "This can be generalized to include k exogenous variables:\n",
    "\n",
    "\n",
    "( )\n",
    "\n",
    "\n",
    "Ideally, we want to form a prediction where, on average, the right-hand side of the equation yields the correct value on the left-hand side. When we perform an OLS regression, we form a predictor that minimizes the sum of the distance between each predicted value and the observed value drawn from the data. For example, if the prediction for a particular value of y is 8, and the actual value is 10, the error of the prediction is -2 and the squared error is 4.\n",
    "\n",
    "To find the function that minimizes the sum squared errors, we will use matrix algebra, also known as linear algebra. For those unfamiliar, the next section uses the numpy library to perform matrix operations. For clarity, we will review the linear algebra functions that we will use with simple examples."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45bcd7fe",
   "metadata": {},
   "source": [
    "### Linear Algebra for OLS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a914be3",
   "metadata": {},
   "source": [
    "### Inverting a Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6562a94b",
   "metadata": {},
   "source": [
    "## Linear Algebra in numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6cd3ac00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 1]\n",
      "[4 1 5]\n",
      "[6 8 6]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "x1 = np.array([1,2,1])\n",
    "x2 = np.array([4,1,5])\n",
    "x3 = np.array([6,8,6])\n",
    "print(x1,x2,x3, sep = \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "056f195c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2 1]]\n",
      "[[4 1 5]]\n",
      "[[6 8 6]]\n"
     ]
    }
   ],
   "source": [
    "x1 = np.matrix(x1)\n",
    "x2 = np.matrix(x2)\n",
    "x3 = np.matrix(x3)\n",
    "print(x1,x2,x3, sep = \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b147aff7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[1, 2, 1],\n",
       "        [4, 1, 5],\n",
       "        [6, 8, 6]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.concatenate((x1, x2, x3))\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aaf51f85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[-8.5000000e+00, -1.0000000e+00,  2.2500000e+00],\n",
       "        [ 1.5000000e+00, -7.6861594e-17, -2.5000000e-01],\n",
       "        [ 6.5000000e+00,  1.0000000e+00, -1.7500000e+00]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_inverse = X.getI()\n",
    "X_inverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c3b3ea4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-8.5 , -1.  ,  2.25],\n",
       "       [ 1.5 , -0.  , -0.25],\n",
       "       [ 6.5 ,  1.  , -1.75]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(X_inverse, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8169090d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[1, 4, 6],\n",
       "        [2, 1, 8],\n",
       "        [1, 5, 6]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_transpose = X.getT()\n",
    "X_transpose"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50dc0a05",
   "metadata": {},
   "source": [
    "## Regression Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e990b52d",
   "metadata": {},
   "source": [
    "Now that we have learned the necessary operations, we can understand the operations of the regression function. If you would like to build your own regression module, reconstruct the scripts form Chapter 7. In this lesson, we will use the statsmodels OLS method to reconstruct and compare statistics from an OLS regression.\n",
    "\n",
    "Recall that we estimate the vector of beta parameters for each variable with the equation:\n",
    "\n",
    "Beta = (X'X)^-1 (X'Y)\n",
    "\n",
    "Each estimated Beta value is multiplied by each observation of the relevant exogenous variable estimate the effect of the value on the endogenous, Y value.\n",
    "\n",
    "We will run a regression In order to estimate the parameters, we will need to import data, define the dependent variable and independent variables, and transform these into matrix objects.\n",
    "\n",
    "Let's use the data from chapter 6 with the addition real GDP per capita. This combined set of data is saved in the repository as a file created in chapter 8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "51d158f3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_16736/3014020480.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m ngdp = pd.read_excel(\"https://www.rug.nl/ggdc/historicaldevelopment/maddison/data/mpd2020.xlsx\",\n\u001b[0m\u001b[0;32m      4\u001b[0m                     \u001b[0mindex_col\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m                     \u001b[0mparse_dates\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "\n",
    "ngdp = pd.read_excel(\"https://www.rug.nl/ggdc/historicaldevelopment/maddison/data/mpd2020.xlsx\",\n",
    "                    index_col = [0, 2],\n",
    "                    parse_dates = True,\n",
    "                    sheet_name = \"Full Data\")\n",
    "ngdp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a48dcc1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b82d33d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rename = {\"Panel Data Summary Index\": \"Summary\",\n",
    "         \"Area 1\": \"Size of Government\",\n",
    "         \"Area 2\": \"Legal System and Property Rights\",\n",
    "         \"Area 3\": \"\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2b822184",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ngdp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_16736/564126093.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"RGDP Per Capita\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mngdp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"gdppc\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'ngdp' is not defined"
     ]
    }
   ],
   "source": [
    "data[\"RGDP Per Capita\"] = ngdp[\"gdppc\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b8210e0b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_16736/1905523378.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mdel\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Standard Deviation of the 5 EFW Areas\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "del data[\"Standard Deviation of the 5 EFW Areas\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def43961",
   "metadata": {},
   "outputs": [],
   "source": [
    "#THIS IS WHERE THE UPDATED DATETIME FORMAT GOES\n",
    "data.reset_index(inplace = True)\n",
    "data[\"Year\"] = data[\"Year\"].astype(str).astype(\"datetime64[ns]\").sort_index()\n",
    "data = data.set_index([\"ISO_Code_3\", \"Year\"]).sort_index()\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c927be90",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_excel(\"EFWAndRGDP.xls\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec0f1829",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data.keys()[3:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d739dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.sort_index(inplace = True)\n",
    "# Transform year to datetime format\n",
    "# Look for update on how to do that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c57ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_vars = list(data.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a439f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_var = [reg_vars[-1]]\n",
    "x_vars = reg_vars[2:-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb76ce4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_data = data[reg_vars]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3a9cfb91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "y = reg_data[y_var]\n",
    "X = reg_data[x_vars]\n",
    "X[\"Constant\"] = 1\n",
    "results = sm.OLS(y, X).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "501865ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e16f3573",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = results.predict()\n",
    "reg_data[y_var[0] + \" Predictor\"] = predictor\n",
    "reg_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1508ff27",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = reg_data[y_var[0] + \" Predictor\"]\n",
    "y_mean = reg_data[y_var[0]].mean()\n",
    "y = reg_data[y_var[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b01e6c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_data[\"Residuals\"] = (y.sub(y_hat))\n",
    "reg_data[\"Squared Explained\"] = y_hat.sub(y_mean).pow(2)\n",
    "reg_data[\"Squared Residuals\"] = y.sub(y_hat).pow(2)\n",
    "reg_data[\"Squared Totals\"] = y.sub(y_mean).pow(2)\n",
    "reg_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a05f51bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "SSR = reg_data[\"Squared Explained\"].sum()\n",
    "SSE = reg_data[\"Squared Residuals\"].sum()\n",
    "SST = reg_data[\"Squared Totals\"].sum()\n",
    "SSR, SSE, SST"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8104433b",
   "metadata": {},
   "source": [
    "##  Calculate Estimator Variance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf5049e3",
   "metadata": {},
   "source": [
    "With the sum of squared errors calculated, the next step is to calculate the estimator variance and use this to construct the covariance matrix. The covariance matrix is used to derive the standard errors and related statistics for each estimated coefficient.\n",
    "\n",
    "We estimate the variance of the error term of the estimator for the dependent variable.\n",
    "\n",
    " \n",
    "\n",
    "number of observations\n",
    "\n",
    "number of independent variables\n",
    "\n",
    "An increase in the number of exogenous variables tends ot increase the fit of a model. By dividing the \n",
    " by degrees of freedom, \n",
    " , improvements in fit that result from increases in the number of variables are offset in part by a reduction in degrees of freedom.\n",
    "\n",
    "Finally, we calculate the covariance matrix, \n",
    ":\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f7b773",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = results.nobs\n",
    "k = len(results.params)\n",
    "estimator_variance = SSE / (n - k)\n",
    "n, k, estimator_variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb7c7d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "cov_matrix = results.cov_params()\n",
    "cov_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a2330bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate covariance matrix by hand\n",
    "XtXInv = np.matrix(matmul(X.T, X)).getI()\n",
    "# multiply by estimator variance\n",
    "ev_mul_XTXInv = estimator_variance * XTXInv\n",
    "# transform to pandas dataframe\n",
    "pd.DataFrame(ev_mul_XTXInv,\n",
    "             columns = X.keys(), index = X.keys()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f80e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8703c226",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"beta\", \"\\t\\t\\tSE\")\n",
    "for x_var in X.keys():\n",
    "    beta_x = results.params[x_var]\n",
    "    StdErrX = cov_matrix.loc[x_var][x_var]**(.5)\n",
    "    #print(beta_x, StdErrX, sep = \"\\t\")\n",
    "    #print(\"t:\", beta_x / StdErrX)\n",
    "    parameters[x_var] = {}\n",
    "    parameters[x_var][\"Beta\"] = beta_x\n",
    "    parameters[x_var][\"SE\"] = StdErrX\n",
    "    parameters[x_var][\"t-stats\"] = beta_x / StdErrX\n",
    "parameters = pd.DataFrame(paramaters).T\n",
    "parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff5f987",
   "metadata": {},
   "source": [
    "## Calculate R^2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8f1ec3f",
   "metadata": {},
   "source": [
    "The variance term will be used to help us calculate other values. First we estimate the square root of the mean squared error. Since the mean squared error is the variance of the estimator, this means we simply take the square root the variance term\n",
    "\n",
    "\n",
    "The square-root of the MSE provides a more readily interpretable estimate of the estimator variance, showing the average distance of predicted values from actual values, corrected for the number of independent variables.\n",
    "\n",
    "We also estimate the R2 value. This value indicates the explanator power of the regression\n",
    "\n",
    " \n",
    "\n",
    "This compares the average squared distance between the predicted values and the average value against the average squared distance between observed values and average values. Ordinary least squares regression minimizes the squared distance between the predicted value and the average value. If values are perfectly predicted, then the SSR would equal the SST. Usually, the SSR is less than the SST. It will never be greater than the SST."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ab0f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2 = SSR / SST\n",
    "r2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72c1c133",
   "metadata": {},
   "source": [
    "## Adjusted R-Squared"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ffc094c",
   "metadata": {},
   "source": [
    "Although the \n",
    " is a useful measure to understand the quality of the explanation provided by the selected exogenous variables. Recall that:\n",
    "\n",
    " \n",
    "\n",
    "Notice that as the degrees of freedom decrease, the numerator necessarily decreases as well. One should not depend solely on the adjusted \n",
    " to consider the strength of a regression's results, but it is often useful to help gauge whether or not a marginal addition of a variable improves explanatory power of a regression.\n",
    "\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b28436be",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_adjusted = 1 - (SSE / (n - k)) / (SST / (n - 1))\n",
    "r2_adjusted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c73928",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "067b74ae",
   "metadata": {},
   "source": [
    "## Common Problems with OLS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab7772b",
   "metadata": {},
   "source": [
    "Although our regression generates a large t-statitic, our errors are not normally distributed. This is due in part to our use of untransformed time-series data. To make the data normally distributed, we could log the data or calculate either the annual difference or percent change. Logging the data will maintain levels. Since this data suffers from a trend, we will calculate the annual difference of index values and the annual percent change of real GDP per capita values after we review the distribution of residuals."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a654919",
   "metadata": {},
   "source": [
    "### Check the distribution of residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e6865e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams.update({\"font.size\":26})\n",
    "fig, ax = plt.subplots(figsize = (12,8))\n",
    "reg_data[[\"Residuals\"]].plot.hist(bins = 100, ax = ax)\n",
    "plt.xticks(rotation = 90)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dc557a2",
   "metadata": {},
   "source": [
    "### Thinking through unit-root and cointegration problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e5a80b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_data.loc[\"USA\"][x_vars + y_var]\n",
    "fig, ax = plt.subplots(figsize = (24, 12))\n",
    "plot_df.diff(5).dropna().plot.line(ax = ax, secondary_y = y_var, legend = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c15d4f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.log(data[y_var]).diff(5).plot.hist(bins = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd1971ef",
   "metadata": {},
   "source": [
    "### WARNING: having more recent data biases estimates toward present inferences from present data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca01d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Regressions with Logged Differences\n",
    "years_diff = 5\n",
    "reg_data = data\n",
    "# take the log of real gdp then difference within group\n",
    "reg_data[\"RGDP Per Capita\"] = np.log(data[\"RGDP Per Capita\"]).groupby(\n",
    "    \"ISO_Code_3\").diff(years_diff)\n",
    "reg_data = reg_data.replace([np.inf, -np.inf], np.NaN)\n",
    "reg_data.loc[\"USA\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df59362b",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_df = reg_data.dropna(axis = 0, how = \"any\")\n",
    "y = r_df[y_var]\n",
    "x = r_df[x_vars]\n",
    "X[\"Constant\"] = 1\n",
    "results = sm.OLS(y, X).fit()\n",
    "r_df[\"Predictor\"] = results.predict()\n",
    "r_df[\"Residuals\"] = results.resid\n",
    "results.summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65876895",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (12, 8))\n",
    "r_df[[\"Residuals\"]].plot.hist(bins = 100, ax = ax)\n",
    "ax.axvline(r_df[\"Residuals\"].mean(), ls = \"- -\", linewidth = 5, color = \"k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b14db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dict = {\"Beta\": results.params,\n",
    "               \"t-stats\": results.tvalues,\n",
    "               \"p-values\": results.pvalues,\n",
    "               \"SE\": results.bse}\n",
    "results_df = pd.DataFrame(results_dict).round(3)\n",
    "results_df.to_csv(\"y = RGDP, x = EFW, LogDiffResults.csv\")\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d765470c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (20, 12))\n",
    "r_df.plot.scatter(x = y_var[0],\n",
    "                 y = \"Predictor\",\n",
    "                 s = 50,\n",
    "                 alpha = .7,\n",
    "                 ax = ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c59bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_vars = y_var + x_vars\n",
    "\n",
    "for var in all_vars:\n",
    "    fig, ax = plt.subplots(figsize = 20, 12)\n",
    "    r_df.plot.scatter(x = var,\n",
    "                     y = \"Residuals\",\n",
    "                     s = 50,\n",
    "                     alpha = .5,\n",
    "                     ax = ax)\n",
    "    ax.axhline(r_df[\"Residuals\"].mean(), ls = \"- -\", linewidth = 5, color = \"k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe694569",
   "metadata": {},
   "outputs": [],
   "source": [
    "for country in countries:\n",
    "    cumulative_data = r_df[[y_var[0], \"Predictor\"]] + 1\n",
    "cumulative_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b5167a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for countries in countries:\n",
    "    try:\n",
    "        plot_data = r_df.loc[country]\n",
    "        fig, ax = plt.subplots(figsize = (20, 10))\n",
    "        plot_data[[y_var[0], \"Predictor\"]].add(1).cumprod().plot.line(ax = ax, legend = True)\n",
    "    except:\n",
    "        print(country + \"does not appear to be in index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a335c37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_df = reg_data.copy()\n",
    "r_df[\"RGDP Per Capita Lag\"] = reg_data[\"RGDP Per Capita\"].groupby(\"ISO_Code_3\").shift(years_diff)\n",
    "r_df = r_df.dropna(axis = 0, how = \"any\")\n",
    "x_vars.append(\"RGDP Per Capita Lag\")\n",
    "y = [y_var]\n",
    "X = [x_vars]\n",
    "X[\"Constant\"] = 1\n",
    "results = sm.OLS(y, x).fit()\n",
    "r_df[\"Predictor\"] = results.predict()\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c1dcdbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_df[\"Residuals\"] = results.resid\n",
    "fig, ax = plt.subplots(figsize = (12,8))\n",
    "\n",
    "r_df[[\"Residuals\"]].plot.hist(bins = 100, ax = ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f8274d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (14,10))\n",
    "r_df.plot.scatter(x = y_var[0],\n",
    "                 y = \"Predictor\", \n",
    "                  s = 30, ax = ax)\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()\n",
    "plt.close()\n",
    "# cycle through all variables included in regression\n",
    "# concantonate y_var and x_vars \n",
    "for var in y_var + x_vars:\n",
    "    fig, ax = plt.subplots(figsize = (14,10))\n",
    "    r_df.plot.scatter(x = y_var[0],\n",
    "                     y = \"Residuals\", \n",
    "                      s = 30, ax = ax)\n",
    "ax.axhline(0, ls = \"--\", color = \"k\")\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()\n",
    "plt.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "743dec84",
   "metadata": {},
   "outputs": [],
   "source": [
    "del r_df[\"Predictor\"]\n",
    "del r_df[\"Residual\"]\n",
    "del r_df[\"RGDP Per Capita Lag\"]\n",
    "# delete RGDP per capita lag for x vars \n",
    "x_vars = r_df.keys()[2:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa3eb9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_vars = list(r_df.keys()[2:7])\n",
    "y_var = [r_df.keys()[7]]\n",
    "x_vars, y_var\n",
    "r_df = r_df[y_var + x_vars].groupby(\"ISO_Code_3\").diff(years_diff).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70aafb32",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_df = r_df.dropna(axis = 0, how = \"any\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab82b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = [y_var]\n",
    "X = [x_vars]\n",
    "# X[\"Constant\"] = 1\n",
    "results = sm.OLS(y, x).fit()\n",
    "r_df[\"Predictor\"] = results.predict()\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfcd1674",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_df[\"Residuals\"] = results.resid\n",
    "fig, ax = plt.subplots(figsize = (12,8))\n",
    "\n",
    "r_df[[\"Residuals\"]].plot.hist(bins = 100, ax = ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa18dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_residuals (df, y_var, x_vars):\n",
    "    fig, ax = plt.subplots(figsize = (14,10))\n",
    "    r_df.plot.scatter(x = y_var[0],\n",
    "                     y = \"Predictor\", \n",
    "                      s = 30, ax = ax)\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "    for var in y_var + x_vars:\n",
    "        fig, ax = plt.subplots(figsize = (14,10))\n",
    "        r_df.plot.scatter(x = y_var[0],\n",
    "                         y = \"Residuals\", \n",
    "                          s = 30, ax = ax)\n",
    "    ax.axhline(0, ls = \"--\", color = \"k\")\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.show()\n",
    "    plt.close() \n",
    "plot_residuals(r_df, y_var, x_vars)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
